{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "TESTING CODE-HEIGHT MAP-MUSTAFA BAL",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "##IMPORTANT LIBRARIES\n\"\"\"\n@author: mbal\n\"\"\"\n\nfrom __future__ import print_function\n\nimport os, glob, sys, threading, random, warnings, fnmatch\nimport shutil, random, json, h5py, re, math\n\nimport cv2\n# import glob2\nimport numpy as np\n\n# # matplotlib.use('agg')\nimport matplotlib.pyplot as plt\n# %matplotlib inline\n\nimport keras\nfrom keras import optimizers\nfrom keras import models\nfrom keras import layers\nfrom keras import backend as K\nfrom keras.models import Model, load_model, Sequential\n\n\nfrom keras.layers import Input, Flatten, Dense, Dropout, Conv2D, concatenate\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\n\nfrom keras.optimizers import RMSprop,Adam, SGD\n\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\n\nfrom keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\nfrom keras.losses import mean_squared_error\nfrom keras.datasets import mnist\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\n\n# from tqdm import tqdm\nfrom itertools import chain\n\nimport scipy.io\nfrom scipy import ndimage, misc\n\nimport sklearn\nfrom skimage.measure import compare_psnr\nfrom skimage.measure import compare_ssim as SSIM\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\n\n# from google.colab import drive\nfrom PIL import Image\n\nfrom natsort import natsorted\nfrom sklearn.utils import shuffle\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\nprint(\"Imported Tensorflow-Keras-OpenCV libraries\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'h5py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mglob\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mthreading\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mrandom\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mfnmatch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mrandom\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mh5py\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# import glob2\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5py'"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "### NORMALIZATION\ndef normalize(input_data): #Normalizing the data\n\treturn (input_data.astype(np.float32))/255\n\ndef denormalize(input_data): #Denormalizing the data\n  input_data = (input_data) * 255\n  return input_data.astype(np.uint8) \n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "main_dir = 'C:/Users/mbal/Desktop/mustafabal/' ## Change this directory with your current folder.\n# /content/drive/My Drive/Research/HeightMAP(CC)/HEIGHTMAP DATASET/HeightMAP_Intensity Mapped\nimport datetime\nnow = datetime.datetime.now()\ndate_time = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\ndef find_missing(lst,x):     \n    return sorted(set(range(0, x )).difference(lst))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "### LOADING THE DATA WITH THE TRAINED MODEL\ndef data_loader(Dataset_Folder):\n  trn_file = h5py.File(main_dir+'Dataset/allnormalised224_'+Dataset_Folder+'_v2_LASTv6.h5','r')\n  \n  X_train = trn_file['HeightMapTrain'][:]\n  Y_train= trn_file['NandSigmaTrain'][:]\n  X_test = trn_file['HeightMapTest'][:]\n  Y_test= trn_file['NandSigmaTest'][:]\n  \n  maxY_trainS=Y_train[:,1].max()  #Normalizing sigma  using global minima and maxima, 24.156723022460938\n  minY_testS=Y_train[:,1].min() # 5.159702301025391\n  maxY_trainN=Y_train[:,0].max()  #normalizing N 3.750767230987549\n  minY_testN=Y_test[:,0].min()  #2.188645124435425\n  \n  print(maxY_trainS)\n  print(maxY_trainN)\n  print(minY_testS)\n  print(minY_testN)\n  \n  Y_train[:,0]= Y_train[:,0]-minY_testN\n  Y_train[:,0]= Y_train[:,0]/(maxY_trainN-minY_testN)\n  \n  Y_test[:,0]= Y_test[:,0]-minY_testN\n  Y_test[:,0]= Y_test[:,0]/(maxY_trainN-minY_testN)\n  \n  Y_train[:,1]= Y_train[:,1]-minY_testS\n  Y_train[:,1]= Y_train[:,1]/(maxY_trainS-minY_testS)\n  \n  Y_test[:,1]= Y_test[:,1]-minY_testS\n  Y_test[:,1]= Y_test[:,1]/(maxY_trainS-minY_testS)\n  \n  print('X_train Size:',np.array(X_train).shape)\n  print('Y_train Size:',np.array(Y_train).shape)\n  print('X_test Size:',np.array(X_test).shape)\n  print('Y_test Size:',np.array(Y_test).shape)\n  print('X_train min-max: ',X_train.min(),X_train.max())\n  print('Y_train S min-max: ',Y_train[:,1].min(),Y_train[:,1].max())\n  print('Y_train N min-max: ',Y_train[:,0].min(),Y_train[:,0].max())\n  print('X_test min-max: ',X_test.min(),X_test.max())\n  print('Y_test N min-max: ',Y_test[:,0].min(),Y_test[:,0].max())\n  print('Y_test S min-max: ',Y_test[:,1].min(),Y_test[:,1].max())\n  print('-----shuffle-----')\n  X_train, Y_train = shuffle(X_train, Y_train, random_state=13)\n \n  print('Y_test N Variance :',np.var(Y_test[:,0]))\n  print('Y_test S Variance :',np.var(Y_test[:,1]))\n  \n  return X_train,Y_train,X_test,Y_test",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "### TESTING RESULT- LOADING VGG-16 AND TRAINED WEIGHTS\nX_train,Y_train,X_test,Y_test = data_loader('900Mhz_300m')\nvgg_conv = models.load_model(main_dir+'Dataset/'+'vgg16_org.h5') ## LOADING VGG-16 MODEL\n# Create the model\nMustafa_Regression = models.Sequential()\n# Add the vgg convolutional base model\nfor layer in vgg_conv.layers[:-1]: # just exclude last layer from copying\n  Mustafa_Regression.add(layer)\nMustafa_Regression.set_weights(vgg_conv.get_weights())\nMustafa_Regression.add(layers.Dense(2, activation='sigmoid'))\nMustafa_Regression.summary()\n\n# ### CHANGE weights\nMustafa_Regression.load_weights(main_dir+'checkpoints/900Mhz_300m_All_Parameters_HEIGHT-48-0.0081.hdf5') # \n\n\n# #Predict on test\npreds_test = Mustafa_Regression.predict(X_test, verbose=1)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'h5py' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### TESTING RESULT- LOADING VGG-16 AND TRAINED WEIGHTS\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train,Y_train,X_test,Y_test \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m900Mhz_300m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m vgg_conv \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mload_model(main_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg16_org.h5\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m## LOADING VGG-16 MODEL\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n",
            "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mdata_loader\u001b[0;34m(Dataset_Folder)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_loader\u001b[39m(Dataset_Folder):\n\u001b[0;32m----> 3\u001b[0m   trn_file \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241m.\u001b[39mFile(main_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset/allnormalised224_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mDataset_Folder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_v2_LASTv6.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m   X_train \u001b[38;5;241m=\u001b[39m trn_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeightMapTrain\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n\u001b[1;32m      6\u001b[0m   Y_train\u001b[38;5;241m=\u001b[39m trn_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNandSigmaTrain\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'h5py' is not defined"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "## RESULTS\npreds_N = preds_test[:,0]\npreds_Sigma = preds_test[:,1]\n\nmaxY_trainS= 24.156723022460938\nminY_testS= 5.159702301025391\nmaxY_trainN= 3.750767230987549\nminY_testN=2.188645124435425\n\nP_S_test=preds_Sigma*(maxY_trainS-minY_testS)\nP_S_test=P_S_test+minY_testS\nprint(P_S_test.max())\n\nP_N_test=preds_N*(maxY_trainN-minY_testN)\nP_N_test=P_N_test+minY_testN\nprint(P_N_test.max())\n\nY_N_test=Y_test[:,0]*(maxY_trainN-minY_testN)\nY_N_test=Y_N_test+minY_testN\nprint(Y_N_test.max())\n\nY_S_test=Y_test[:,1]*(maxY_trainS-minY_testS)\nY_S_test=Y_S_test+minY_testS\nprint(Y_S_test.max())\n\nprint('Denormalized MSE N: ',np.mean((Y_N_test-P_N_test)**2))\nprint('Denormalized MSE Sigma: ',np.mean((Y_S_test-P_S_test)**2))\n\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfig3=plt.figure()\nplt.xlim(2,4)\nplt.ylim(2,4)\nplt.scatter(Y_N_test, P_N_test)\nplt.xlabel(\"True\",fontsize='20')\nplt.ylabel(\"Predicted\",fontsize='20')\nplt.title(\"True vs predicted $n$ (height maps)\",fontsize='20')\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\n# plt.savefig(\"C:/Users/mbal/Desktop/mustafabal/Wireless Communication Letter Reviews/WC_ALLPARAMETERS_HEIGHT_N_Scatter_VGG16.pdf\",bbox_inches='tight')\nplt.show()\n\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfig3=plt.figure()\nplt.xlim(4,26)\nplt.ylim(4,26)\nplt.scatter(Y_S_test, P_S_test)\nplt.xlabel(\"True\",fontsize='20')\nplt.ylabel(\"Predicted\",fontsize='20')\nplt.title(\"True vs predicted $\\sigma$ (height maps)\",fontsize='20')\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\n# plt.savefig(\"C:/Users/mbal/Desktop/mustafabal/Wireless Communication Letter Reviews/WC_ALLPARAMETERS_HEIGHT_Sigma_Scatter_VGG16.pdf\",bbox_inches='tight')\nplt.show()\n\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.patches as mpatches\nm = np.array((np.array(Y_N_test),np.array(P_N_test)))\n# print(m[0][0],m[1][0])Y_S_test=Y_train[:,1]*(maxY_trainS-minY_testS)\n# Y_S_test=Y_S_test+minY_testS\nprint(Y_S_test.shape)\nsortedArr = m [ :, m[0].argsort()]\nprint('Sorted 2D Numpy Array')\nprint(sortedArr[0][0],sortedArr[1][0])\nGT=sortedArr[0]\nPred=sortedArr[1]\nfig1=plt.figure()\nx1 = np.linspace(0, 241, 241)\nplt.plot(x1,GT,'r.',x1,Pred,'.')\nplt.xlabel(\"Test sample numbers\",fontsize='20')\nplt.ylabel(\"$n$ values\",fontsize='20')\nplt.title(\"True vs predicted $n$ values from height maps\",fontsize='20')\nred_patch = mpatches.Patch(color='red', label='True $n$')\nblue_patch = mpatches.Patch(color='cornflowerblue', label='Predicted $n$')\nplt.legend(handles=[red_patch,blue_patch],prop={\"size\":18})\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\nplt.grid(True)\n# plt.savefig(\"C:/Users/mbal/Desktop/mustafabal/Wireless Communication Letter Reviews/AllParameters_HEIGHT_N.pdf\",bbox_inches='tight')\n\n\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.patches as mpatches\nm = np.array((np.array(Y_S_test),np.array(P_S_test)))\n# print(m[0][0],m[1][0])\nsortedArr = m [ :, m[0].argsort()]\nprint('Sorted 2D Numpy Array')\nprint(sortedArr[0][0],sortedArr[1][0])\nGT=sortedArr[0]\nPred=sortedArr[1]\nfig1=plt.figure()\nx1 = np.linspace(0, 241, 241)\nplt.plot(x1,GT,'r.',x1,Pred,'.')\nplt.xlabel(\"Test sample numbers\",fontsize='20')\nplt.ylabel(\"$\\sigma$ values\",fontsize='20')\nplt.title(\"True vs predicted $\\sigma$ values from height maps\",fontsize='20')\nred_patch = mpatches.Patch(color='red', label='True $\\sigma$')\nblue_patch = mpatches.Patch(color='cornflowerblue', label='Predicted $\\sigma$')\nplt.legend(handles=[red_patch,blue_patch],prop={\"size\":18})\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\nplt.grid(True)\n# plt.savefig(\"C:/Users/mbal/Desktop/mustafabal/Wireless Communication Letter Reviews/AllParameters_HEIGHT_Sigma.pdf\",bbox_inches='tight')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'preds_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## RESULTS\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m preds_N \u001b[38;5;241m=\u001b[39m \u001b[43mpreds_test\u001b[49m[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m preds_Sigma \u001b[38;5;241m=\u001b[39m preds_test[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m maxY_trainS\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24.156723022460938\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preds_test' is not defined"
          ],
          "output_type": "error"
        }
      ]
    }
  ]
}